{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df18a50",
   "metadata": {},
   "source": [
    "# **Aim:** To predict emotions from a text using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0621a1",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f889f6",
   "metadata": {},
   "source": [
    "### Importing Header Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6981e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a29cd",
   "metadata": {},
   "source": [
    "### Initializing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42cba7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/jt/Python/Research/preds/training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0acba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 0\",axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f9b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(i):\n",
    "    entity_prefixes = ['@','#']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in entity_prefixes :\n",
    "            i = i.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in i.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb05395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Length\"] = df[\"Tweet\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62cf195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2686/3905470843.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Tweet\"][i] = clean_tweet(df[\"Tweet\"][i])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df)):\n",
    "    df[\"Tweet\"][i] = clean_tweet(df[\"Tweet\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c2a4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e16e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet'] = df['Tweet'].map(lambda text:re.sub('[^a-zA-Z0-9]+', ' ',text)).apply(lambda x: (x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367471a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1d9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "df[\"Tweet\"] = df['Tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040b8895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2686/3549973974.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Tweet'] = df['Tweet'].str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "df['Tweet'] = df['Tweet'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "255ed9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2686/506338351.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df[\"Tweet\"] = df[\"Tweet\"].str.replace(\"$\",\"\")\n"
     ]
    }
   ],
   "source": [
    "df[\"Tweet\"] = df[\"Tweet\"].str.replace(\"$\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "762b82f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vet vechain vefam start voting</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cryptocurrencies going disappoint looking use ...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes think btc going ath run next week get futu...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sunday charting frens wanna share think bullis...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petty invectives wasabi aside one clearest con...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20685</th>\n",
       "      <td>space nft slogan xyz ok let bet future</td>\n",
       "      <td>Joy</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20686</th>\n",
       "      <td>thinking moving non eth farming ftm avax bc</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20687</th>\n",
       "      <td>fi   avax fee really</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20688</th>\n",
       "      <td>stats price   cmc rank circulating supply    a...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20689</th>\n",
       "      <td>ant uncommon colony stage  sold   avax</td>\n",
       "      <td>Joy</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20690 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet   Emotion Length\n",
       "0                         vet vechain vefam start voting  Surprise     51\n",
       "1      cryptocurrencies going disappoint looking use ...       Joy    257\n",
       "2      yes think btc going ath run next week get futu...       Joy    118\n",
       "3      sunday charting frens wanna share think bullis...       Joy    213\n",
       "4      petty invectives wasabi aside one clearest con...      Fear    142\n",
       "...                                                  ...       ...    ...\n",
       "20685             space nft slogan xyz ok let bet future       Joy    181\n",
       "20686        thinking moving non eth farming ftm avax bc   Sadness     93\n",
       "20687                               fi   avax fee really   Sadness     38\n",
       "20688  stats price   cmc rank circulating supply    a...       Joy    183\n",
       "20689             ant uncommon colony stage  sold   avax       Joy     66\n",
       "\n",
       "[20690 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea570654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df[\"Emotion\"] == \"Joy\"]\n",
    "df2 = df[df[\"Emotion\"] == \"Surprise\"]\n",
    "df3 = df[df[\"Emotion\"] == \"Fear\"]\n",
    "df4 = df[df[\"Emotion\"] == \"Sadness\"]\n",
    "df5 = df[df[\"Emotion\"] == \"Anger\"]\n",
    "df6 = df[df[\"Emotion\"] == \"Disgust\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f2cb15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c1 = Counter(\" \".join(df1[\"Tweet\"]).split()).most_common()\n",
    "c2 = Counter(\" \".join(df2[\"Tweet\"]).split()).most_common()\n",
    "c3 = Counter(\" \".join(df3[\"Tweet\"]).split()).most_common()\n",
    "c4 = Counter(\" \".join(df4[\"Tweet\"]).split()).most_common()\n",
    "c5 = Counter(\" \".join(df5[\"Tweet\"]).split()).most_common()\n",
    "c6 = Counter(\" \".join(df6[\"Tweet\"]).split()).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64008b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_2 = []\n",
    "c3_4 = []\n",
    "c5_6 = []\n",
    "c1_2_and_c3_4 = []\n",
    "c3_4_and_c5_6 = []\n",
    "finalcommon = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f1deb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_2 = set(c1)&set(c2) \n",
    "c3_4 = set(c3)&set(c4)\n",
    "c5_6 = set(c5)&set(c6)\n",
    "\n",
    "c1_2final = sorted(c1_2)\n",
    "c3_4final = sorted(c3_4)\n",
    "c5_6final = sorted(c5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef1deeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_2_and_c3_4 = set(c1_2)&set(c3_4)\n",
    "c3_4_and_c5_6 = set(c3_4)&set(c5_6)\n",
    "\n",
    "c1_2_and_c3_4final = sorted(c1_2_and_c3_4)\n",
    "c3_4_and_c5_6final = sorted(c3_4_and_c5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5d0f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_2_and_c5_6 = set(c1_2)&set(c5_6)\n",
    "c1_2_and_c5_6final = sorted(c1_2_and_c5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77f083b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalcommon = set(c1_2_and_c3_4)&set(c3_4_and_c5_6)\n",
    "final = sorted(finalcommon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4cbf6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_2_final_df = pd.DataFrame(c1_2final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "286332f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(c1_2final).to_csv(\"Common Words between Joy and Suprise.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "602ed09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(c3_4final).to_csv(\"Common Words between Fear and Sadness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71699717",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(c5_6final).to_csv(\"Common Words between Anger and Disgust.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71a862d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(c1_2_and_c3_4final).to_csv(\"Common Words between Joy,Suprise and Fear,sadness.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88c884a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(c3_4_and_c5_6final).to_csv(\"Common Words between Fear,sadness and Anger,Disgust.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b15359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(final).to_csv(\"common of all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca34d424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
